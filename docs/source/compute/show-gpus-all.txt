Kubernetes contexts {'non-exist-k8s-context', 'gke_sky-dev-465_us-central1-c_skypilotalpha', 'kind-skypilot'} specified in "allowed_contexts" not found in kubeconfig. Ignoring these contexts.
Kubernetes contexts {'non-exist-k8s-context', 'gke_sky-dev-465_us-central1-c_skypilotalpha', 'kind-skypilot'} specified in "allowed_contexts" not found in kubeconfig. Ignoring these contexts.
Note: No GPUs found in any Kubernetes clusters. If your cluster contains GPUs, make sure nvidia.com/gpu resource is available on the nodes and the node labels for identifying GPUs (e.g., skypilot.co/accelerator) are setup correctly. To further debug, run: sky check Note: No GPUs found in any SSH clusters. If your cluster contains GPUs, make sure nvidia.com/gpu resource is available on the nodes and the node labels for identifying GPUs (e.g., skypilot.co/accelerator) are setup correctly. To further debug, run: sky check 

ERROR:asyncio:Task was destroyed but it is pending!
task: <Task pending name='Task-51' coro=<Bearer.bg_task.<locals>.wrapper() running at /opt/conda/lib/python3.10/site-packages/nebius/aio/token/renewable.py:136> wait_for=<Future pending cb=[Task.task_wakeup()]> cb=[Bearer.bg_task.<locals>.<lambda>() at /opt/conda/lib/python3.10/site-packages/nebius/aio/token/renewable.py:143, _wait.<locals>._on_completion() at /opt/conda/lib/python3.10/asyncio/tasks.py:475]>
ERROR:asyncio:Task was destroyed but it is pending!
task: <Task pending name='Task-43' coro=<Bearer.bg_task.<locals>.wrapper() running at /opt/conda/lib/python3.10/site-packages/nebius/aio/token/renewable.py:136> wait_for=<Future pending cb=[Task.task_wakeup()]> cb=[Bearer.bg_task.<locals>.<lambda>() at /opt/conda/lib/python3.10/site-packages/nebius/aio/token/renewable.py:143]>
ERROR:asyncio:Task was destroyed but it is pending!
task: <Task pending name='Task-50' coro=<Bearer.bg_task.<locals>.wrapper() running at /opt/conda/lib/python3.10/site-packages/nebius/aio/token/renewable.py:136> wait_for=<Future pending cb=[Task.task_wakeup()]> cb=[Bearer.bg_task.<locals>.<lambda>() at /opt/conda/lib/python3.10/site-packages/nebius/aio/token/renewable.py:143]>
COMMON_GPU  AVAILABLE_QUANTITIES  
A10         1, 2, 4               
A10G        1, 4, 8               
A100        1, 2, 4, 8, 16        
A100-80GB   1, 2, 4, 8            
H100        1, 2, 4, 8, 12        
H200        1, 4, 8               
L4          1, 2, 4, 8            
L40S        1, 2, 4, 8            
T4          1, 2, 4, 8            
V100        1, 2, 4, 8            
V100-32GB   1, 2, 4, 8            

GOOGLE_TPU       AVAILABLE_QUANTITIES  
tpu-v2-8         1                     
tpu-v3-8         1                     
tpu-v4-8         1                     
tpu-v4-16        1                     
tpu-v4-32        1                     
tpu-v5litepod-1  1                     
tpu-v5litepod-4  1                     
tpu-v5litepod-8  1                     
tpu-v5p-8        1                     
tpu-v5p-16       1                     
tpu-v5p-32       1                     
tpu-v6e-1        1                     
tpu-v6e-4        1                     
tpu-v6e-8        1                     

OTHER_GPU          AVAILABLE_QUANTITIES  
A100-80GB-SXM      1, 2, 4, 8            
A40                1, 2, 4, 8            
A4000              1, 2, 4               
A6000              1, 2, 4               
B200               1, 2, 4, 8            
GH200              1                     
Gaudi HL-205       8                     
H100-MEGA          8                     
H100-NVL           1, 2, 4, 8            
H100-NVLINK        8                     
H100-SXM           1, 2, 4, 8            
K80                1, 2, 4               
L40                1, 2, 4, 8            
M4000              1                     
M60                1, 2, 4               
MI300X             1, 2, 4, 8            
NVIDIA             8                     
P100               1, 2, 4               
P4                 1, 2, 4               
P4000              1, 2                  
RTX3060            1, 2, 4               
RTX3080            1                     
RTX3090            1, 2, 4, 8, 10        
RTX4000-Ada        1, 2, 4, 8            
RTX4090            1, 2, 4, 8, 12        
RTX5060            2, 4                  
RTX5070            4                     
RTX5080            1                     
RTX5090            1, 2, 4, 8            
RTX6000            1                     
RTX6000-Ada        1, 2, 4, 8            
RTXA4000           1, 2, 4, 8            
RTXA4500           1, 2, 4, 8            
RTXA5000           1, 2, 4, 8            
RTXA6000           1, 2, 4, 8            
Radeon MI25        1                     
Radeon Pro V520    1, 2, 4               
T4g                1, 2                  
... [omitted long outputs] ...
